{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MuammerEren1/AcademyGen/blob/main/AcademyGen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4v0KDGVpdZdb"
      },
      "outputs": [],
      "source": [
        "# (run this first)\n",
        "\n",
        "!pip install requests gradio pdfplumber nltk transformers torch\n",
        "!pip install openai\n",
        "!pip install openai==0.28\n",
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 688
        },
        "id": "BNj74NIVd549",
        "outputId": "f5687321-119f-4062-cd20-9f34196458ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://22142b9f59bf0bb16f.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://22142b9f59bf0bb16f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://22142b9f59bf0bb16f.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# (run this second)\n",
        "# by Muammer Eren\n",
        "# Thank you for reviewing :)\n",
        "# Note: Don't forget to run the cells in order to open the app\n",
        "\n",
        "import gradio as gr\n",
        "import pdfplumber\n",
        "import openai\n",
        "import os\n",
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "# OpenAI API key for GPT usage.\n",
        "openai.api_key = \"API-KEY\" #You must enter your own API Key here.\n",
        "\n",
        "# First it takes the text text as clean as possible from the pdf file\n",
        "# This function here, cleans up text by removing extra spaces and unwanted characters\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'\\s+', ' ', text)  # This replaces multiple spaces with one\n",
        "    text = re.sub(r'[^\\w\\s.,!?;:-]', '', text)  # Remove unwanted characters\n",
        "    return text.strip()  # Remove spaces from start and end\n",
        "\n",
        "# This function breaks text into sentences\n",
        "def simple_sentence_tokenize(text):\n",
        "    sentences = re.split(r'(?<=[.!?])\\s+(?=[A-Z])', text)  # Split by punctuation followed by uppercase\n",
        "    return [s.strip() for s in sentences if s.strip()]  # Remove empty sentences\n",
        "\n",
        "# Extracts text from a PDF file\n",
        "def extract_text_from_pdf(pdf_file):\n",
        "  # Open a PDF and extract all the text page by page.\n",
        "    with pdfplumber.open(pdf_file) as pdf:\n",
        "        text_chunks = []\n",
        "        for page in pdf.pages:\n",
        "            if page.extract_text(): # Check if the page has text.\n",
        "                text_chunks.append(clean_text(page.extract_text()))  # Clean and save the text.\n",
        "        return \" \".join(text_chunks)\n",
        "\n",
        "# Divides the text into smaller parts for better processing\n",
        "def chunk_text(text, max_chunk_size=10000):\n",
        "    sentences = simple_sentence_tokenize(text)  # getting sentences\n",
        "    chunks = []  # Store text parts here\n",
        "    current_chunk = []\n",
        "    current_length = 0\n",
        "\n",
        "    for sentence in sentences:\n",
        "        if current_length + len(sentence) > max_chunk_size and current_chunk:\n",
        "            chunks.append(\" \".join(current_chunk))  # Add current chunk to list\n",
        "            current_chunk = [sentence]  # this starts a new chunk\n",
        "            current_length = len(sentence)\n",
        "        else:\n",
        "            current_chunk.append(sentence)\n",
        "            current_length += len(sentence)\n",
        "\n",
        "    if current_chunk:  # adds any leftover sentences\n",
        "        chunks.append(\" \".join(current_chunk))\n",
        "\n",
        "    return chunks\n",
        "\n",
        "# Adjust text to match the target word count\n",
        "def truncate_to_word_limit(text, target_words):\n",
        "  # Shorten or expand text to match a specific word count\n",
        "    words = text.split()\n",
        "    current_words = len(words)\n",
        "\n",
        "    # Check if text is too short and expand it using OpenAI\n",
        "    if current_words < target_words * 0.9:  # expands if short\n",
        "        try:\n",
        "            additional_words_needed = target_words - current_words\n",
        "            expansion_prompt = f\"\"\"The current content is too short. Please add approximately {additional_words_needed} more words.\n",
        "            Previous content: {text}\"\"\"\n",
        "\n",
        "            response = openai.ChatCompletion.create(\n",
        "                model=\"gpt-4o-mini\",\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You are an expert at expanding educational content naturally.\"},\n",
        "                    {\"role\": \"user\", \"content\": expansion_prompt}\n",
        "                ],\n",
        "                max_tokens=4000,\n",
        "                temperature=0.7\n",
        "            )\n",
        "\n",
        "            additional_text = response['choices'][0]['message']['content'].strip()\n",
        "            text += \"\\n\\n\" + additional_text\n",
        "            words = text.split()\n",
        "        except Exception as e:\n",
        "            print(f\"Error expanding content: {str(e)}\")\n",
        "\n",
        "    # If text is too long, truncate it to the word limit\n",
        "    if len(words) > target_words:  # Cut off if too long\n",
        "        sentences = simple_sentence_tokenize(\" \".join(words[:target_words + 50]))\n",
        "        truncated_text = \"\"\n",
        "        word_count = 0\n",
        "\n",
        "        for sentence in sentences:\n",
        "            sentence_words = len(sentence.split())\n",
        "            if word_count + sentence_words > target_words:\n",
        "                break\n",
        "            truncated_text += sentence + \" \"\n",
        "            word_count += sentence_words\n",
        "\n",
        "        return truncated_text.strip()\n",
        "\n",
        "    return text\n",
        "\n",
        "# Creates a section of the educational material based on the text\n",
        "def generate_chat_section(text, section_type, word_count_option):\n",
        "  # Creates sections (e.g., introduction, examples) using OpenAI\n",
        "    try:\n",
        "      # defines word counts for different lecture lengths\n",
        "        word_counts = {\n",
        "            \"30 minutes\": {'introduction': (500, 550), 'detailed': (1800, 1900), 'examples': (1200, 1300), 'summary': (500, 550)},\n",
        "            \"60 minutes\": {'introduction': (1500, 1600), 'detailed': (4500, 4700), 'examples': (2500, 2700), 'summary': (1000, 1100)}\n",
        "        }\n",
        "\n",
        "        target_words, max_words = word_counts[word_count_option][section_type]\n",
        "        prompts = {\n",
        "            'introduction': f\"Write a {target_words}-word introduction for students. Use friendly tone. Make the content engaging and easy to understand while covering foundational concepts and setting expectations for deeper learning.\",\n",
        "            'detailed': f\"Provide {target_words}-word detailed explanations. Make the subject easy to understand. Ensure comprehensive coverage of the subject with a focus on clarity.\",\n",
        "            'examples': f\"Give {target_words}-word practical examples. Include step-by-step solutions and real-life uses.\",\n",
        "            'summary': f\"Write a {target_words}-word summary and suggest next steps for students. Recap key points in simple terms and outline clear, actionable steps for further understanding.\"\n",
        "        }\n",
        "\n",
        "        system_prompt = \"You are an expert at creating educational content. Make sure to generate content with the exact word count. Use friendly tone and make sure the content is not repetitive at all. What you generate should be understandable and clear, ensure the language is accessible and suitable for learners of all levels.\"\n",
        "\n",
        "        prompt = f\"{prompts[section_type]}\\n\\nContext from the document:\\n{text[:30000]}\"\n",
        "\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": prompt}],\n",
        "            max_tokens=8000,\n",
        "            temperature=0.7\n",
        "        )\n",
        "        generated_text = response['choices'][0]['message']['content'].strip()\n",
        "        return truncate_to_word_limit(generated_text, target_words)\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error generating {section_type} section: {str(e)}\"\n",
        "\n",
        "# Format the output for readability\n",
        "def format_output(sections):\n",
        "    formatted_output = \"\"\n",
        "    for title, content in [\n",
        "        (\"1. Introduction to the Subject\", sections['introduction']),\n",
        "        (\"2. Detailed Explanation of the Subject\", sections['detailed']),\n",
        "        (\"3. Practical Examples and Solutions\", sections['examples']),\n",
        "        (\"4. Summary and Next Steps for Students\", sections['summary'])\n",
        "    ]:\n",
        "        formatted_output += f\"\\n{title}\\n{'=' * len(title)}\\n{content}\\n\\n\"\n",
        "    return formatted_output\n",
        "\n",
        "# Main function for processing PDF\n",
        "def process_pdf(pdf_file, word_count_option):\n",
        "  #Process the PDF and generate lecture notes.\n",
        "    try:\n",
        "        if not pdf_file:\n",
        "            return \"Please upload a PDF file.\"\n",
        "\n",
        "        text = extract_text_from_pdf(pdf_file)  # get text from PDF\n",
        "        if not text.strip():\n",
        "            return \"No text found in the PDF.\"\n",
        "\n",
        "        sections = {}\n",
        "        chunks = chunk_text(text)\n",
        "        context_text = \" \".join(chunks[:3])\n",
        "\n",
        "        for section_type in ['introduction', 'detailed', 'examples', 'summary']:\n",
        "            sections[section_type] = generate_chat_section(context_text, section_type, word_count_option)\n",
        "\n",
        "        return format_output(sections)\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {str(e)}\"\n",
        "\n",
        "# Here is the Gradio user interface of the app\n",
        "with gr.Blocks(theme=gr.themes.Soft()) as iface:\n",
        "    gr.Markdown(\n",
        "        \"\"\"\n",
        "        # 📚 AcademyGen - AI Lecture Note Generator by Muammer Eren\n",
        "\n",
        "        Transform any educational content into well-structured lecture notes. It may take few minutes to generate.\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=2):\n",
        "            file_input = gr.File(\n",
        "                label=\"Upload a PDF Transcript\",\n",
        "                file_types=[\".pdf\"],\n",
        "                elem_id=\"file_input\"\n",
        "            )\n",
        "            duration = gr.Dropdown(\n",
        "                choices=[\"30 minutes\", \"60 minutes\"],\n",
        "                label=\"Lecture Duration\",\n",
        "                value=\"30 minutes\",\n",
        "                elem_id=\"duration_dropdown\"\n",
        "            )\n",
        "            submit_btn = gr.Button(\"Generate Lecture Notes\", variant=\"primary\")\n",
        "\n",
        "            gr.Markdown(\n",
        "                \"\"\"\n",
        "                ### Instructions:\n",
        "                1. Upload a PDF file containing your teaching material\n",
        "                2. Select the desired lecture duration\n",
        "                3. Click 'Generate Teaching Material' to create your content\n",
        "\n",
        "                ### Duration Guide:\n",
        "                - 30 minutes ≈ 3,900 words\n",
        "                - 60 minutes ≈ 9,000 words\n",
        "                \"\"\"\n",
        "            )\n",
        "\n",
        "        with gr.Column(scale=3):\n",
        "            output_text = gr.Textbox(\n",
        "                label=\"Generated Lecture Notes\",\n",
        "                lines=30,\n",
        "                elem_id=\"output_text\"\n",
        "            )\n",
        "\n",
        "    submit_btn.click(\n",
        "        fn=process_pdf,\n",
        "        inputs=[file_input, duration],\n",
        "        outputs=output_text,\n",
        "        api_name=\"generate_content\"\n",
        "    )\n",
        "\n",
        "    gr.Markdown(\n",
        "        \"\"\"\n",
        "        ### Made By Muammer Eren\n",
        "        AcademyGen helps all educators create comprehensive and well-structured lecture notes from any transcript.\n",
        "        These are the contents that will be generated:\n",
        "        - Clear introduction to the subject\n",
        "        - Detailed explanations of key concepts\n",
        "        - Practical examples and solutions\n",
        "        - Summary and next steps for students\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "# Launching\n",
        "iface.launch(debug=True)\n",
        "\n",
        "# How prompts were engineered and refined:\n",
        "# I write the prompts carefully with specific educational roles (introduction, detailed explanation, examples, and summary) and I tested them many times to ensure they generate clear, understandable, structured content\n",
        "\n",
        "#Challenges faced and solutions:\n",
        "#The main challenges were handling long documents and adjusting fast and correct responses, which were solved by implementing efficient text chunking and smart processing of key document portions.\n",
        "\n",
        "#How the system can be extended or scaled:\n",
        "#The system can scale to serve more users with content creation in different languages, separate logins per user, and database consolidation."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPkcDTnbmGStHgncz00G2Zx",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}